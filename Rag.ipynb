{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87c3dd4f",
   "metadata": {},
   "source": [
    "**Reference Link**: https://github.com/DataTalksClub/llm-zoomcamp/tree/main/01-intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fc92659-c84d-41ab-82ef-c7e36297d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2494e136",
   "metadata": {},
   "source": [
    "### Reading the faq llm zoomcamp file which is in json format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9a7420a-149f-45aa-8ad0-ffa3186739db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('documents-llm.json', 'rt') as f_in:\n",
    "    docs_raw = json.load(f_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645eddf8",
   "metadata": {},
   "source": [
    "We are adding the course inside the documents which contains text, question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d37d4211",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "\n",
    "for course_dict in docs_raw:\n",
    "    for doc in course_dict['documents']:\n",
    "        doc['course'] = course_dict['course']\n",
    "        documents.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62bd00a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Yes, but if you want to receive a certificate, you need to submit your project while we‚Äôre still accepting submissions.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'I just discovered the course. Can I still join?',\n",
       " 'course': 'llm-zoomcamp'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da09eb62",
   "metadata": {},
   "source": [
    "We are trying to do RAG implementation using Elastic search.\n",
    "\n",
    "### üß† RAG (Retrieval-Augmented Generation)\n",
    "**RAG** is a technique used in natural language processing (NLP) to improve the quality of generated text by retrieving relevant documents before generating a response.\n",
    "\n",
    "### üîç How RAG Works:\n",
    " **Retrieval Phase:**\n",
    "- A query is sent to a document store (like a vector database).\n",
    "- The system retrieves relevant documents or passages based on semantic similarity.\n",
    "\n",
    "**Generation Phase:**\n",
    "- A language model (like GPT) uses the retrieved documents as context.\n",
    "- It generates a response that‚Äôs grounded in the retrieved information.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53063695",
   "metadata": {},
   "source": [
    "#### üîé Elasticsearch\n",
    "**Elasticsearch** is a search engine based on Lucene, designed for fast and scalable full-text search.\n",
    "\n",
    "**‚öôÔ∏è Key Features:**\n",
    "- Indexing: Stores data in a structured format for fast retrieval.\n",
    "- Search: Supports keyword search, fuzzy search, and filtering.\n",
    "- Analytics: Can perform aggregations and visualizations (often used with Kibana).\n",
    "\n",
    "**üß† How It Works:**\n",
    "- Data is stored in JSON documents.\n",
    "- You can query using a powerful DSL (Domain Specific Language).\n",
    "- It‚Äôs optimized for text search, log analysis, and real-time data exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9f86546",
   "metadata": {},
   "source": [
    "To run elastic search using Docker, run the following command in command line/terminal\n",
    "\n",
    "docker run -it \\\n",
    "    --rm \\\n",
    "    --name elasticsearch \\\n",
    "    -m 4GB \\\n",
    "    -p 9200:9200 \\\n",
    "    -p 9300:9300 \\\n",
    "    -e \"discovery.type=single-node\" \\\n",
    "    -e \"xpack.security.enabled=false\" \\\n",
    "    docker.elastic.co/elasticsearch/elasticsearch:8.4.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "26c70f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from elasticsearch import Elasticsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e5e6faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "es_client = Elasticsearch('http://localhost:9200') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc30ec19",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'es_client' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[33;03m\"\"\" number_of_shards = 1\u001b[39;00m\n\u001b[32m     17\u001b[39m \n\u001b[32m     18\u001b[39m \u001b[33;03mShards are like splitting your folder into smaller subfolders so Elasticsearch can search faster.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     38\u001b[39m \n\u001b[32m     39\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     41\u001b[39m index_name = \u001b[33m\"\u001b[39m\u001b[33mcourse-questions\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43mes_client\u001b[49m.indices.create(index=index_name, body=index_settings)\n",
      "\u001b[31mNameError\u001b[39m: name 'es_client' is not defined"
     ]
    }
   ],
   "source": [
    "index_settings = {\n",
    "    \"settings\": {\n",
    "        \"number_of_shards\": 1,\n",
    "        \"number_of_replicas\": 0\n",
    "    }, \n",
    "    \"mappings\": {\n",
    "        \"properties\": {\n",
    "            \"text\": {\"type\": \"text\"},\n",
    "            \"section\": {\"type\": \"text\"},\n",
    "            \"question\": {\"type\": \"text\"},\n",
    "            \"course\": {\"type\": \"keyword\"} \n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\"\"\" number_of_shards = 1\n",
    "\n",
    "Shards are like splitting your folder into smaller subfolders so Elasticsearch can search faster.\n",
    "\n",
    "Here, 1 means we‚Äôre keeping everything in a single shard (good for small datasets).\n",
    "\n",
    "number_of_replicas = 0\n",
    "\n",
    "Replicas are backup copies of your shards for fault tolerance.\n",
    "\n",
    "Here, 0 means no backups ‚Äî fine for testing, but risky for production.\n",
    "\n",
    "Mapping part defines the structure of the data in the index ‚Äî like setting column types in a database.\n",
    "\n",
    "- text, section, question ‚Üí type: \"text\"\n",
    "- These fields will be analyzed for full-text search.\n",
    "- Elasticsearch will tokenize and index them for efficient matching.\n",
    "\n",
    "- course ‚Üí type: \"keyword\"\n",
    "- This field is not analyzed.\n",
    "- Used for exact matches, filtering, and aggregations (e.g., grouping by course name).\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "index_name = \"course-questions\"\n",
    "\n",
    "es_client.indices.create(index=index_name, body=index_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e6d5703f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Yes, but if you want to receive a certificate, you need to submit your project while we‚Äôre still accepting submissions.',\n",
       " 'section': 'General course-related questions',\n",
       " 'question': 'I just discovered the course. Can I still join?',\n",
       " 'course': 'llm-zoomcamp'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e8c7684",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc499dcf",
   "metadata": {},
   "source": [
    "Code is inserting documents into your \"course-questions\" index in Elasticsearch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5e9e6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33ad2c0118c450da5a36e6459562970",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/86 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for doc in tqdm(documents):\n",
    "    es_client.index(index=index_name, document=doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99160d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"how to get access to saturn cloud\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f62902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def elastic_search(query):\n",
    "    search_query = {\n",
    "        \"size\": 5, #This means: only return 5 documents (results).\n",
    "        \"query\": {\n",
    "            \"bool\": { #A bool query in Elasticsearch lets you combine conditions ‚Äî like saying must match this AND must pass that filter.\n",
    "                \"must\": {\n",
    "                    \"multi_match\": { #multi_match = Search for the same query across multiple fields.\n",
    "                        \"query\": query,\n",
    "                        \"fields\": [\"question^3\", \"text\", \"section\"], #\"question^3\" ‚Üí The ^3 means boost the importance of matches in question by 3√ó., also search in text and section fields.\n",
    "                        \"type\": \"best_fields\" #Choose the single best field match for scoring.\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": { #Filters are used to narrow down the search results.\n",
    "                    \"term\": { #term = Search for a term in a specific field.\n",
    "                        \"course\": \"llm-zoomcamp\" #Search for the term \"llm-zoomcamp\" in the \"course\" field. \n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    response = es_client.search(index=index_name, body=search_query)\n",
    "    \n",
    "    result_docs = []\n",
    "    \n",
    "    for hit in response['hits']['hits']: #Loop through the hits (results) and extract the relevant information.\n",
    "        result_docs.append(hit['_source']) #Append the source of the hit (the document) to the result_docs list.\n",
    "    \n",
    "    return result_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6998b28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Please see the General section or use CTRL+F to search this doc.',\n",
       "  'section': 'Module 2: Open-Source LLMs',\n",
       "  'question': 'Saturn Cloud issues',\n",
       "  'course': 'llm-zoomcamp'},\n",
       " {'text': 'Issue: I get the notice that due to traffic, I‚Äôm on a waitlist for new signups.\\nAnswer: There was a form to submit our emails to, so Alexey can send it in bulk. If you missed that deadline, just sign up manually (or via request tech demo link) and use the chat to request for free hours for ‚Äúllm zoomcamp‚Äù\\nIssue: I‚Äôm a pre-existing user from a different zoomcamp and I‚Äôm not awarded the free hours even though I‚Äôve submitted my email in the form.\\nAnswer: Just request it via their chat, after you‚Äôve logged in using your pre-existing account, citing ‚Äúllm zoomcamp‚Äù .',\n",
       "  'section': 'General course-related questions',\n",
       "  'question': 'SaturnCloud - How do I get access?',\n",
       "  'course': 'llm-zoomcamp'},\n",
       " {'text': 'Manually set the token as below:\\naccess_token = <your_token>\\nmodel  = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-v0.1\", token=access_token)\\ntokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-v0.1\", token=access_token)',\n",
       "  'section': 'Module 2: Open-Source LLMs',\n",
       "  'question': 'Mistral AI: Unable to get Mistral-7B-v0.1 access despite accepting terms on HF',\n",
       "  'course': 'llm-zoomcamp'},\n",
       " {'text': 'Clean out your cache using the following code:\\nfrom transformers import TRANSFORMERS_CACHE\\nprint(TRANSFORMERS_CACHE)\\nimport shutil\\nshutil.rmtree(TRANSFORMERS_CACHE)\\nNote: Make sure to shutdown the notebook and restart the kernel',\n",
       "  'section': 'Module 2: Open-Source LLMs',\n",
       "  'question': 'SaturnCloud: How can I clean out the hugging face model cache on a saturn cloud notebook?',\n",
       "  'course': 'llm-zoomcamp'},\n",
       " {'text': '1. search with the model name on hugging face.\\n2. get the transformer used on the model.\\n3. using the transformer, encode the string you want.\\n4. calculate the length of the outputted tensor.\\nThe previous code snippet uses the tokenizer of google/gemma-2b LLM. \\nDon‚Äôt forget to make your token secret.\\nAdded by kamal',\n",
       "  'section': 'Module 2: Open-Source LLMs',\n",
       "  'question': 'HuggingFace: How to get the number of tokens in a certain string related to a certain model on hugging face?',\n",
       "  'course': 'llm-zoomcamp'}]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_results = elastic_search(query)\n",
    "search_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e165142b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Libraries Required\n",
    "%pip install langchain-huggingface --quiet\n",
    "## For API Calls\n",
    "%pip install huggingface_hub --quiet\n",
    "%pip install transformers --quiet\n",
    "%pip install accelerate --quiet\n",
    "%pip install  bitsandbytes --quiet\n",
    "%pip install langchain --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032dba28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: dotenv in /home/codespace/.local/share/virtualenvs/llm-zoomcamp-B9pnCD16/lib/python3.12/site-packages (0.9.9)\n",
      "Requirement already satisfied: python-dotenv in /home/codespace/.local/share/virtualenvs/llm-zoomcamp-B9pnCD16/lib/python3.12/site-packages (from dotenv) (1.1.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "%pip install dotenv \n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7b5518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0c446b",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n",
    "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]=key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b9709b",
   "metadata": {},
   "source": [
    "Calling LLM from hugging face model hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1790fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from huggingface_hub import InferenceClient\n",
    "\n",
    "\n",
    "def llm(prompt):\n",
    "    client = InferenceClient(\n",
    "        provider=\"groq\",\n",
    "        api_key=key,\n",
    "    )\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"openai/gpt-oss-120b\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36e7b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(query, search_results):\n",
    "    prompt_template = \"\"\"\n",
    "You're a course teaching assistant. Answer the QUESTION based on the CONTEXT from the FAQ database.\n",
    "Use only the facts from the CONTEXT when answering the QUESTION.\n",
    "\n",
    "QUESTION: {question}\n",
    "\n",
    "CONTEXT: \n",
    "{context}\n",
    "\"\"\".strip()\n",
    "\n",
    "    context = \"\"\n",
    "    \n",
    "    for doc in search_results:\n",
    "        context = context + f\"section: {doc['section']}\\nquestion: {doc['question']}\\nanswer: {doc['text']}\\n\\n\" \n",
    "        \n",
    "    \"\"\"Loops through each doc from Elasticsearch search results.\n",
    "\n",
    "        For each document:\n",
    "\n",
    "        Adds the section name.\n",
    "\n",
    "        Adds the FAQ question from the DB.\n",
    "\n",
    "        Adds the answer (stored in text).\n",
    "\n",
    "        Each entry is separated by a blank line for readability.\"\"\"\n",
    "            \n",
    "    prompt = prompt_template.format(question=query, context=context).strip()\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3199895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag(query):\n",
    "    search_results = elastic_search(query) #getting the relevant results from elastic search\n",
    "    prompt = build_prompt(query, search_results) #passing the results with query and prompt in a proper format to llm\n",
    "    answer = llm(prompt) #getting the answer from hugging face llm\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f4f84e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**How to get access to Saturn\\u202fCloud for the LLM Zoomcamp**\\n\\n1. **Submit your email**  \\n   - There was a shared form where you could submit your email address. Alexey used that list to grant access in bulk.  \\n   - **If you missed that deadline**, simply sign up on the Saturn\\u202fCloud site (or use the ‚Äúrequest tech demo‚Äù link) and then **use the Saturn\\u202fCloud chat** to ask for free hours, mentioning **‚Äúllm zoomcamp.‚Äù**\\n\\n2. **If you already have a Saturn\\u202fCloud account from a previous Zoomcamp**  \\n   - Log in with your existing account.  \\n   - Open the Saturn\\u202fCloud chat and request the free hours, again citing **‚Äúllm zoomcamp.‚Äù**  \\n\\nThe key steps are:\\u202fsubmit your email (or sign up manually), then request the free ‚ÄúLLM Zoomcamp‚Äù hours via the chat (or have Alexey add you if you‚Äôre on the original email list).'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "query=\"how to get access to saturn cloud\"\n",
    "rag(query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-zoomcamp-B9pnCD16",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
